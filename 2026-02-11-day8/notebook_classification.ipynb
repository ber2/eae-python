{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Día 8: Clasificación y Cierre del Curso\n",
    "\n",
    "**Introducción a Python para ML** | EAE Business School | 11 febrero 2026\n",
    "\n",
    "**¡Último día!** Hoy vamos a aprender clasificación con regresión logística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 0: Visualización regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos 500 apuestas al azar; queremos estudiar la probabilidad de ganar.\n",
    "n_bids = 500\n",
    "bids = np.random.uniform(0, 10, n_bids)\n",
    "\n",
    "real_win = np.random.uniform(5, 9, 1)[0]\n",
    "wins = np.where(bids > real_win + np.random.normal(size=n_bids), 1.0, 0.0)\n",
    "\n",
    "\n",
    "\n",
    "# Entrenamos una regresión logística para aprender los coeficientes.\n",
    "lr = LogisticRegression()\n",
    "lr.fit(bids.reshape(-1, 1), wins)\n",
    "beta_0 = lr.intercept_[0]\n",
    "beta_1 = lr.coef_[0,0]\n",
    "\n",
    "pred_win = lr.predict(bids.reshape(-1, 1))\n",
    "\n",
    "# Visualizamos los resultados\n",
    "df = pd.DataFrame({\n",
    "    \"bids\": bids,\n",
    "    \"wins\": wins,\n",
    "    \"pred\": pred_win.astype(np.bool),\n",
    "})\n",
    "\n",
    "xs = np.linspace(0.0, 10.0, 100)\n",
    "sgs = 1 / (1 + np.exp(- beta_0 - beta_1 * xs))\n",
    "\n",
    "fig = px.scatter(\n",
    "    df,\n",
    "    x=\"bids\",\n",
    "    y=\"wins\",\n",
    "    #color=\"pred\",\n",
    "    title=f\"real = {real_win:.2f}, beta_0 = {beta_0:.2f}, beta_1 = {beta_1:.2f}\"\n",
    ")\n",
    "#fig.add_trace(go.Scatter(x=xs, y=sgs, name=\"Logistic Reg\"))\n",
    "#fig.add_vline(x=-beta_0/beta_1)\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1: Cargar Datos Hotel Bookings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/ber2/eae-python/main/data/hotel_bookings.csv'\n",
    "df = pd.read_csv(url)\n",
    "print(f'Shape: {df.shape}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explorar target\n",
    "print(df['is_canceled'].value_counts())\n",
    "print(f'\\nTasa de cancelación: {df[\"is_canceled\"].mean():.1%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: Preparar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar features numéricas\n",
    "features = ['lead_time', 'stays_weekend_nights', 'stays_week_nights', \n",
    "            'adults', 'previous_cancellations', 'booking_changes', \n",
    "            'days_in_waiting_list']\n",
    "\n",
    "X = df[features].fillna(df[features].median())\n",
    "y = df['is_canceled']\n",
    "\n",
    "print(f'Features: {X.shape[1]}')\n",
    "print(f'Samples: {len(X)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f'Train: {len(X_train)}, Test: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3: Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline: predecir siempre la clase mayoritaria (no cancela)\n",
    "baseline_pred = np.zeros(len(y_test))\n",
    "baseline_acc = accuracy_score(y_test, baseline_pred)\n",
    "print(f'Baseline Accuracy: {baseline_acc:.3f}')\n",
    "print('Nuestro modelo debe superar este baseline!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 4: Entrenar Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "print('✓ Modelo entrenado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones\n",
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probabilidad clase 1\n",
    "\n",
    "print('Primeras 10 probabilidades:')\n",
    "for i in range(10):\n",
    "    print(f'Sample {i}: P(cancelar) = {y_proba[i]:.2f}, Predicción: {y_pred[i]}, Real: {y_test.iloc[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 5: Evaluar Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusión\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(cm)\n",
    "\n",
    "fig = px.imshow(cm, text_auto=True,\n",
    "                labels=dict(x='Predicho', y='Real'),\n",
    "                x=['No Cancela', 'Cancela'],\n",
    "                y=['No Cancela', 'Cancela'],\n",
    "                title='Matriz de Confusión')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métricas\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy:  {acc:.3f}')\n",
    "print(f'Precision: {prec:.3f}')\n",
    "print(f'Recall:    {rec:.3f}')\n",
    "print(f'F1-Score:  {f1:.3f}')\n",
    "print(f'\\nMejora sobre baseline: {acc - baseline_acc:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 6: Interpretar Coeficientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features más importantes\n",
    "coefs = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Coeficiente': model.coef_[0]\n",
    "}).sort_values('Coeficiente', key=abs, ascending=False)\n",
    "\n",
    "print('\\nFeatures más influyentes:')\n",
    "print(coefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 7: Ajustar Umbral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probar diferentes umbrales\n",
    "for threshold in [0.3, 0.5, 0.7]:\n",
    "    y_pred_thresh = (y_proba >= threshold).astype(int)\n",
    "    acc_t = accuracy_score(y_test, y_pred_thresh)\n",
    "    prec_t = precision_score(y_test, y_pred_thresh)\n",
    "    rec_t = recall_score(y_test, y_pred_thresh)\n",
    "    print(f'\\nUmbral {threshold}:')\n",
    "    print(f'  Accuracy: {acc_t:.3f}, Precision: {prec_t:.3f}, Recall: {rec_t:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio: workflow completo con el dataset original\n",
    "\n",
    "1. Explorar datos\n",
    "2. Limpiar y preparar\n",
    "3. Train/test split (o cross validation si se quiere rizar el rizo)\n",
    "4. Feature engineering: fabricar nuevas features, añadir features categóricas\n",
    "5. Entrenar `LogisticRegression`\n",
    "6. Evaluar y comparar contra baseline (dummy, predecir que nunca habrá cancelación)\n",
    "7. Interpretar coeficientes\n",
    "8. Ajustar umbral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/ber2/eae-python/main/data/hotel_bookings_large.csv'\n",
    "df_large = pd.read_csv(url)\n",
    "print(f'Shape: {df_large.shape}')\n",
    "df_large.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
